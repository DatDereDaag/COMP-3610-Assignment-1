{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec146178",
   "metadata": {},
   "source": [
    "Part 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7019f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the data\n",
    "\n",
    "import requests\n",
    "import os \n",
    "\n",
    "#This is the directory where the files are stored\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "#We then make a function to call to download each file\n",
    "def download_file(url, destination_path):\n",
    "    print(f\"Beginning download of {url}...\")\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status() # Check if request was successful\n",
    "\n",
    "        #We then open the file to download the data to\n",
    "        with open(destination_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "\n",
    "        print(f\"Download completed and saved to {destination_path}.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while downloading {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "919cbc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning download of https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet...\n",
      "Download completed and saved to data/raw/yellow_tripdata_2024-01.parquet.\n",
      "Beginning download of https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv...\n",
      "Download completed and saved to data/raw/taxi_zone_lookup.csv.\n",
      "All files downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "#Using our previous download helper function, we download the two required files\n",
    "\n",
    "yellow_taxi_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
    "taxi_zone_url = \"https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv\"\n",
    "\n",
    "download_file(yellow_taxi_url, \"data/raw/yellow_tripdata_2024-01.parquet\")\n",
    "download_file(taxi_zone_url, \"data/raw/taxi_zone_lookup.csv\")\n",
    "\n",
    "print(\"All files downloaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68492497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now load the data in a polars dataframe for data validation\n",
    "#Polars is used for further processing due to its speed advantages over pandas for larger datasets such as this one\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "#Load the datasets\n",
    "taxi_trip_df = pl.read_parquet(\"data/raw/yellow_tripdata_2024-01.parquet\")\n",
    "taxi_zone_df = pl.read_csv(\"data/raw/taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4511acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying all expected columns exist\n",
    "\n",
    "expected_columns = {\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"tip_amount\",\n",
    "    \"total_amount\",\n",
    "    \"payment_type\",\n",
    "}\n",
    "\n",
    "for col in expected_columns:\n",
    "    if col not in taxi_trip_df.columns:\n",
    "        raise Exception(f\"Missing column: {col} in the taxi trip dataset, aborting...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d87f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking date columns are of valid datetime type\n",
    "\n",
    "date_columns = [\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"]\n",
    "\n",
    "for col in date_columns:\n",
    "    #The below if state checks if the column for the two essential date columns is of datetime type of the various measurement units\n",
    "    if taxi_trip_df[col].dtype not in (pl.Datetime, pl.Datetime(\"us\"), pl.Datetime(\"ms\"), pl.Datetime(\"ns\")):\n",
    "        raise Exception(f\"Column {col} is not of datetime type, aborting...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d289c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Data Validation: \n",
      "\n",
      "All expected columns are present in the taxi trip dataset.\n",
      "Date columns are of valid datetime type in taxi trip dataset. \n",
      "\n",
      "Total number of rows in taxi trip dataset: 2964624\n",
      "Total number of rows in taxi zone dataset: 265\n",
      "\n",
      "Taxi trip dataset schema: \n",
      " Schema([('VendorID', Int32), ('tpep_pickup_datetime', Datetime(time_unit='ns', time_zone=None)), ('tpep_dropoff_datetime', Datetime(time_unit='ns', time_zone=None)), ('passenger_count', Int64), ('trip_distance', Float64), ('RatecodeID', Int64), ('store_and_fwd_flag', String), ('PULocationID', Int32), ('DOLocationID', Int32), ('payment_type', Int64), ('fare_amount', Float64), ('extra', Float64), ('mta_tax', Float64), ('tip_amount', Float64), ('tolls_amount', Float64), ('improvement_surcharge', Float64), ('total_amount', Float64), ('congestion_surcharge', Float64), ('Airport_fee', Float64)])\n",
      "Taxi zone dataset schema: \n",
      " Schema([('LocationID', Int64), ('Borough', String), ('Zone', String), ('service_zone', String)])\n",
      "\n",
      "Data validation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#Printing a summary of the data validation to the console\n",
    "print(\"Summary of Data Validation: \\n\")\n",
    "\n",
    "print(\"All expected columns are present in the taxi trip dataset.\")\n",
    "print(\"Date columns are of valid datetime type in taxi trip dataset. \\n\")\n",
    "\n",
    "print(f\"Total number of rows in taxi trip dataset: {len(taxi_trip_df)}\")\n",
    "print(f\"Total number of rows in taxi zone dataset: {len(taxi_zone_df)}\\n\")\n",
    "\n",
    "print(f\"Taxi trip dataset schema: \\n {taxi_trip_df.schema}\")\n",
    "print(f\"Taxi zone dataset schema: \\n {taxi_zone_df.schema}\\n\")\n",
    "\n",
    "print(\"Data validation completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d7f66",
   "metadata": {},
   "source": [
    "Part 2: Data Transformation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e448c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now sanitize the data for preparation for analysis\n",
    "\n",
    "#First we clean up any rows with null values in important columns such as pick and dropoff times, locations, fares and trips\n",
    "\n",
    "important_columns = [\n",
    "    \"tpep_pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"fare_amount\",\n",
    "    \"trip_distance\"\n",
    "]\n",
    "\n",
    "row_count_before_null_filter = len(taxi_trip_df)\n",
    "\n",
    "taxi_trip_df = taxi_trip_df.drop_nulls(subset=important_columns)\n",
    "\n",
    "#Record the number of rows removed for later documentation\n",
    "removed_null_rows = row_count_before_null_filter - len(taxi_trip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d8207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now clean the data by removing any rows where the trip has zero or negative distance, negative fares, or fares exceeding $500\n",
    "\n",
    "rows_before_invalid_filter = len(taxi_trip_df)\n",
    "\n",
    "taxi_trip_df = taxi_trip_df.filter(\n",
    "    pl.col(\"trip_distance\") > 0,\n",
    "    pl.col(\"fare_amount\") >= 0,\n",
    "    pl.col(\"fare_amount\") <= 500\n",
    ")\n",
    "\n",
    "removed_invalid_rows = rows_before_invalid_filter - len(taxi_trip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd9d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For our last bit of sanitization we then remove rows where dropoff time is before pickup time\n",
    "\n",
    "rows_before_dropoff_filter = len(taxi_trip_df)\n",
    "\n",
    "taxi_trip_df = taxi_trip_df.filter(\n",
    "    pl.col(\"tpep_dropoff_datetime\") >= pl.col(\"tpep_pickup_datetime\")\n",
    ")\n",
    "\n",
    "removed_dropoff_rows = rows_before_dropoff_filter - len(taxi_trip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd0888df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Sanitization Summary: \n",
      "\n",
      "Total rows before sanitization were: 2964624 \n",
      "\n",
      "Rows removed due to null values in important columns: 0\n",
      "Rows remaining after removing null values were: 2964624 \n",
      "\n",
      "Rows removed due to invalid trip distance or fare amount: 94466\n",
      "Rows remaining after removing invalid trip distance or fare amount were: 2870158\n",
      "\n",
      "Rows removed due to dropoff time before pickup time: 56\n",
      "\n",
      "Total rows removed during sanitization were: 94522\n",
      "Total remaining rows in dataset: 2870102 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Documenting the sanitization results\n",
    "\n",
    "print(\"Data Sanitization Summary: \\n\")\n",
    "\n",
    "print(f\"Total rows before sanitization were: {row_count_before_null_filter} \\n\")\n",
    "\n",
    "print(f\"Rows removed due to null values in important columns: {removed_null_rows}\")\n",
    "print(f\"Rows remaining after removing null values were: {rows_before_invalid_filter} \\n\")\n",
    "\n",
    "print(f\"Rows removed due to invalid trip distance or fare amount: {removed_invalid_rows}\")\n",
    "print(f\"Rows remaining after removing invalid trip distance or fare amount were: {rows_before_dropoff_filter}\\n\")\n",
    "\n",
    "print(f\"Rows removed due to dropoff time before pickup time: {removed_dropoff_rows}\\n\")\n",
    "\n",
    "print(f\"Total rows removed during sanitization were: {removed_null_rows + removed_invalid_rows + removed_dropoff_rows}\")\n",
    "print(f\"Total remaining rows in dataset: {len(taxi_trip_df)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a1c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next we do feature engineering to add our own derived columns to the dataset\n",
    "\n",
    "#Adding trip duration in minutes\n",
    "taxi_trip_df = taxi_trip_df.with_columns([\n",
    "    ((pl.col(\"tpep_dropoff_datetime\") - pl.col(\"tpep_pickup_datetime\"))\n",
    "     .dt.total_seconds() / 60)\n",
    "     .alias(\"trip_duration_minutes\")\n",
    "])\n",
    "\n",
    "#Adding trip speed in mph\n",
    "taxi_trip_df = taxi_trip_df.with_columns([\n",
    "    pl.when(pl.col(\"trip_duration_minutes\") > 0)\n",
    "      .then(pl.col(\"trip_distance\") / (pl.col(\"trip_duration_minutes\") / 60))\n",
    "      .otherwise(None)\n",
    "      .alias(\"trip_speed_mph\")\n",
    "])\n",
    "\n",
    "#Adding pickup hour\n",
    "taxi_trip_df = taxi_trip_df.with_columns([\n",
    "    pl.col('tpep_pickup_datetime').dt.hour().alias('pickup_hour')\n",
    "])\n",
    "\n",
    "#Adding pickup day of week\n",
    "taxi_trip_df = taxi_trip_df.with_columns([\n",
    "    pl.col('tpep_pickup_datetime').dt.strftime(\"%A\").alias('pickup_day_of_week')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5444de9",
   "metadata": {},
   "source": [
    "What are the top 10 busiest pickup zones by total number of trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3ee950c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pickup_zone  total_trips\n",
      "0                Midtown Center       140161\n",
      "1         Upper East Side South       140134\n",
      "2                   JFK Airport       138478\n",
      "3         Upper East Side North       133975\n",
      "4                  Midtown East       104356\n",
      "5     Times Sq/Theatre District       102972\n",
      "6  Penn Station/Madison Sq West       102161\n",
      "7           Lincoln Square East       101800\n",
      "8             LaGuardia Airport        87715\n",
      "9         Upper West Side South        86475\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Create a DuckDB connection\n",
    "con = duckdb.connect()\n",
    "\n",
    "#Register dataframes\n",
    "con.register(\"taxi_trips\", taxi_trip_df)\n",
    "con.register(\"taxi_zones\", taxi_zone_df)\n",
    "\n",
    "busiest_pickup_zones = con.execute('''\n",
    "    SELECT \n",
    "        z.\"Zone\" AS pickup_zone,\n",
    "        COUNT(*) AS total_trips\n",
    "    FROM\n",
    "        taxi_trips t\n",
    "    JOIN\n",
    "        taxi_zones z \n",
    "            ON t.PULocationID = z.LocationID\n",
    "    GROUP BY \n",
    "        z.\"Zone\"\n",
    "    ORDER BY \n",
    "        total_trips DESC\n",
    "    LIMIT 10\n",
    "                                  \n",
    "'''\n",
    ").fetchdf()\n",
    "\n",
    "print(busiest_pickup_zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a9a09",
   "metadata": {},
   "source": [
    " What is the average fare amount for each hour of the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44b916fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pickup_hour  avg_fare_amount\n",
      "0             0        19.679250\n",
      "1             1        17.732032\n",
      "2             2        16.621723\n",
      "3             3        18.530033\n",
      "4             4        23.435229\n",
      "5             5        27.492713\n",
      "6             6        22.026585\n",
      "7             7        18.749879\n",
      "8             8        17.822939\n",
      "9             9        17.943989\n",
      "10           10        18.047523\n",
      "11           11        17.628112\n",
      "12           12        17.796520\n",
      "13           13        18.418805\n",
      "14           14        19.271523\n",
      "15           15        19.110366\n",
      "16           16        19.457290\n",
      "17           17        18.118545\n",
      "18           18        17.013712\n",
      "19           19        17.626564\n",
      "20           20        18.050403\n",
      "21           21        18.292862\n",
      "22           22        19.110051\n",
      "23           23        20.243498\n"
     ]
    }
   ],
   "source": [
    "average_fair = con.execute(''' \n",
    "    SELECT \n",
    "        pickup_hour,\n",
    "        AVG(fare_amount) as avg_fare_amount\n",
    "    FROM\n",
    "        taxi_trips\n",
    "    GROUP BY \n",
    "       pickup_hour\n",
    "    ORDER BY \n",
    "        pickup_hour\n",
    "''').fetchdf()\n",
    "\n",
    "print(average_fair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f912be",
   "metadata": {},
   "source": [
    "What percentage of trips use each payment type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f06c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   payment_type payment_method  percentage_of_trips\n",
      "0             0          Other             4.015363\n",
      "1             1    Credit card            80.081196\n",
      "2             2           Cash            14.735400\n",
      "3             3      No charge             0.370997\n",
      "4             4        Dispute             0.797045\n"
     ]
    }
   ],
   "source": [
    "payment_type_perc = con.execute(''' \n",
    "    SELECT \n",
    "        payment_type,        \n",
    "        CASE payment_type\n",
    "            WHEN 1 THEN 'Credit card'\n",
    "            WHEN 2 THEN 'Cash'\n",
    "            WHEN 3 THEN 'No charge'\n",
    "            WHEN 4 THEN 'Dispute'\n",
    "            WHEN 5 THEN 'Unknown'\n",
    "            ELSE 'Other'\n",
    "        END AS payment_method,\n",
    "        COUNT(*) * 100.0 / SUM(COUNT(*)) OVER () AS percentage_of_trips\n",
    "    FROM\n",
    "        taxi_trips\n",
    "    GROUP BY \n",
    "        payment_type\n",
    "    ORDER BY\n",
    "        payment_type                    \n",
    "''').fetchdf()\n",
    "\n",
    "print(payment_type_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b97ad8",
   "metadata": {},
   "source": [
    "What is the average tip percentage (tip_amount/fare_amount) by day of week, for\n",
    "credit card payments only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52542db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pickup_day_of_week  avg_tip_percentage\n",
      "0             Friday           25.595719\n",
      "1             Monday           25.513977\n",
      "2           Saturday           26.293897\n",
      "3             Sunday           25.100984\n",
      "4           Thursday           29.734458\n",
      "5            Tuesday           25.729989\n",
      "6          Wednesday           25.706582\n"
     ]
    }
   ],
   "source": [
    "avg_tip_perc = con.execute(''' \n",
    "    SELECT \n",
    "        pickup_day_of_week,\n",
    "        AVG(tip_amount/NULLIF(fare_amount, 0)) * 100 as avg_tip_percentage\n",
    "    FROM\n",
    "        taxi_trips\n",
    "    WHERE\n",
    "        payment_type = 1\n",
    "    GROUP BY \n",
    "        pickup_day_of_week\n",
    "    ORDER BY\n",
    "        pickup_day_of_week                    \n",
    "''').fetchdf()\n",
    "\n",
    "print(avg_tip_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4f7be3",
   "metadata": {},
   "source": [
    "What are the top 5 most common pickup-dropoff zone pairs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4bf1e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pickup_zone           dropoff_zone  total_trips\n",
      "0  Upper East Side South  Upper East Side North        21642\n",
      "1  Upper East Side North  Upper East Side South        19199\n",
      "2  Upper East Side North  Upper East Side North        15200\n",
      "3  Upper East Side South  Upper East Side South        14119\n",
      "4         Midtown Center  Upper East Side South        10139\n"
     ]
    }
   ],
   "source": [
    "pickup_dropoff_pair = con.execute(''' \n",
    "    SELECT \n",
    "        pick_up.\"Zone\" as pickup_zone,\n",
    "        drop_off.\"Zone\" as dropoff_zone,\n",
    "        COUNT(*) AS total_trips\n",
    "    FROM\n",
    "        taxi_trips t\n",
    "    JOIN taxi_zones pick_up\n",
    "        ON t.PULocationID = pick_up.LocationID\n",
    "    JOIN taxi_zones drop_off\n",
    "        ON t.DOLocationID = drop_off.LocationID\n",
    "    GROUP BY \n",
    "        pickup_zone, \n",
    "        dropoff_zone\n",
    "    ORDER BY \n",
    "        total_trips DESC    \n",
    "    LIMIT 5\n",
    "''').fetchdf()\n",
    "\n",
    "print(pickup_dropoff_pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
